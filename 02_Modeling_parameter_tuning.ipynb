{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import Model, get99, splitData, dropMissingValues, z_score, outliers_knn, outliers_dbscan, getNoise, getRelFeatures, drop_features, getCombinations, get_unique_list, bold, blue, red, green, getBestModel, np_to_df, df_to_np, drop99_all, z_score_individual\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file\n",
    "f = open ('data/json/input.json', \"r\")\n",
    "  # Reading from file\n",
    "PARAMETERS = json.loads(f.read())\n",
    "\n",
    "SPLIT_SIZE = PARAMETERS[\"SPLIT_SIZE\"]\n",
    "\n",
    "OUTLIER99 = PARAMETERS[\"OUTLIER99\"] \n",
    "\n",
    "OUTLIER_ZSCORE_IND = PARAMETERS[\"OUTLIER_ZSCORE_IND\"]\n",
    "\n",
    "OUTLIER_ZSCORE = {\"STD\" : [10.1, 10.2, 10.3, 10.4]}\n",
    "OUTLIER_KNN = {\"K\": [3], \"X\": [1400, 1600]}\n",
    "OUTLIER_DBSCAN = {\"K\": [3,4], \"X\": [500,1500], \"EPS\": [0.5], \"MIN_SAMPLES\":  [6.6]}\n",
    "OUTLIER_NOISE = {\"CV\": [2.5, 3, 3.5], \"DEPTH\":[3,5], \"MULTI\": [5,10]}\n",
    "\n",
    "FEATURE_SEL_CORR = {\"THRESHOLD_CORR\": [0.2, 0.25, 0.35]}\n",
    "\n",
    "f.close()\n",
    "\n",
    "#TODO FEATURE\n",
    "#TODO Regressionmodels\n",
    "#TODO TESTDATA --> path to csv-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get raw Data\n",
    "df = pd.read_csv(\"data/csv/house_data_training.csv\", sep=';') \n",
    "# remove unnamed column\n",
    "df = df.iloc[:, 1:]\n",
    "#Transform string to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "maeList = []#for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropMissingValues(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     # Outlier Detection\n",
    "#     outlier_dict_all = {}\n",
    "\n",
    "#     if OUTLIER99 == True:\n",
    "#         print(\"outlier_99\")\n",
    "#         outlier_list_99 = get99(df) #TODO Mean for price for trainingsdata\n",
    "#         df = drop99_all(df, outlier_list_99 )\n",
    "#         #outlier_dict_all[\"99_mean\"] = outlier_list_99\n",
    "#         #outlier_dict_all[\"99_drop\"] = outlier_list_99\n",
    "#         print(\"done\\n\")\n",
    "\n",
    "#     print('starting z_score')\n",
    "#     for p in OUTLIER_ZSCORE[\"STD\"]:\n",
    "#         print(p)\n",
    "#         outlier_list_z_score = z_score(df, p)\n",
    "#         outlier_dict_all[\"z_score_\"+str(p)] = outlier_list_z_score\n",
    "\n",
    "#     ''''''\n",
    "#     outlier_lists_all = list(outlier_dict_all.values())\n",
    "#     outlier_lists_keys = list(outlier_dict_all.keys())\n",
    "#     combination_list = []\n",
    "#     for i, combo in enumerate(getCombinations(outlier_lists_keys), 1):\n",
    "#         if not i == 1: #emtpy tuple\n",
    "#             combination_list.append(combo)\n",
    "#             # print('combo #{}: {}'.format(i, combo))\n",
    "#     #print(\"...\")\n",
    "#     #for c in combination_list[10:]:\n",
    "#         #print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "#     #print(bold(len(combination_list)), \" total Combinations\")\n",
    "\n",
    "#     model_obj_list = []\n",
    "#     for i, c in enumerate(combination_list):\n",
    "#         #print(f'\\n{bold(i)}: {blue(c)}')\n",
    "#         outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "#         try: \n",
    "#             if \"99_mean\" in c:\n",
    "#                 X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"both\", outlier_list_99)\n",
    "#             else:\n",
    "#                 X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "\n",
    "#             #TODO Regressionmodels\n",
    "#             model = LinearRegression()\n",
    "#             obj = Model(model, (X_train, X_test, y_train, y_test), c, df)\n",
    "#             model_obj_list.append(obj)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(bold(\"Error\"), red(e))\n",
    "\n",
    "#     #Summary\n",
    "#     df_summary = pd.DataFrame(columns=['combo', 'mae', 'score'])\n",
    "#     for o in model_obj_list:\n",
    "#         #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "#         o.train()\n",
    "#         mae, score = o.summary()\n",
    "#         comb = o.get_comb()\n",
    "#         row = {'combo': comb, 'mae': mae, 'score': score}\n",
    "#         df_summary = df_summary.append(row, ignore_index=True)\n",
    "\n",
    "#     df_summary.sort_values(\"mae\").head()\n",
    "\n",
    "#     ##row\n",
    "#     mae_best = df_summary[df_summary.mae==df_summary.mae.min()]\n",
    "#     score_best = df_summary[df_summary.score==df_summary.score.max()]\n",
    "#     best_model_obj = getBestModel(model_obj_list, df_summary, mae_best.index[0])\n",
    "#     print(best_model_obj)\n",
    "#     #print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "#     model_obj_list_best = [best_model_obj]\n",
    "#     df_feature_reduction = best_model_obj.get_df().head()\n",
    "\n",
    "#     # print(df_feature_reduction)\n",
    "\n",
    "#     ###Feature\n",
    "#     for threshold in FEATURE_SEL_CORR[\"THRESHOLD_CORR\"]:\n",
    "#         #print(threshold, type(threshold))\n",
    "#         try: \n",
    "#             rel_features = getRelFeatures(df_feature_reduction, threshold)\n",
    "#             #print(len(rel_features), rel_features)\n",
    "#             df_feature_reduction = df_feature_reduction[rel_features]\n",
    "#             X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "#             best_model_obj_new = Model(best_model_obj.get_model(), (X_train, X_test, y_train, y_test), best_model_obj.get_comb() , df_feature_reduction)\n",
    "#             # best_model_obj_new.train()\n",
    "#             model_obj_list_best.append(best_model_obj_new)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(bold(\"Error\"), red(e))\n",
    "#     #print(model_obj_list_best)\n",
    "\n",
    "#     #Summary\n",
    "#     df_summary_best = pd.DataFrame(columns=['combo', 'mae', 'score', 'features'])\n",
    "#     for o in model_obj_list_best:\n",
    "#         #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "#         o.train()\n",
    "#         mae, score = o.summary()\n",
    "#         comb = o.get_comb()\n",
    "#         features = o.get_df().columns.to_list()\n",
    "#         features.remove(\"price\")\n",
    "#         row = {'combo': comb, 'mae': mae, 'score': score, 'features': features}\n",
    "#         df_summary_best = df_summary_best.append(row, ignore_index=True)\n",
    "\n",
    "#     #df_summary_best.sort_values(\"mae\")\n",
    "\n",
    "#     #row\n",
    "#     mae_best = df_summary_best[df_summary_best.mae==df_summary_best.mae.min()]\n",
    "#     score_best = df_summary_best[df_summary_best.score==df_summary_best.score.max()]\n",
    "#     best_model_obj = getBestModel(model_obj_list_best, df_summary_best, mae_best.index[0])\n",
    "#     print(best_model_obj)\n",
    "#     print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "#     lines = f'{df_summary_best[\"combo\"][0]} - {df_summary_best[\"mae\"][0]} - {len(df_summary_best[\"features\"][0])} ' \n",
    "\n",
    "#     #import os.path\n",
    "#     #file_exists = os.path.exists('parameter_search.txt')\n",
    "#     # if file_exists == False:\n",
    "#     #     with open('parameter_search.txt', 'w') as f:\n",
    "#     #         f.write('Create a new text file!')\n",
    "\n",
    "#     with open('parameter_search.txt', 'a+') as f:\n",
    "#         for line in lines:\n",
    "#             f.write(line)\n",
    "#         f.write('\\n')\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier_99\n",
      "done\n",
      "\n",
      "done \n",
      "\n",
      "starting knn\n",
      "3 1400\n",
      "3 1600\n",
      "dropped \u001b[31m1400\u001b[0m / 1400 rows\n",
      "dropped \u001b[31m1600\u001b[0m / 1600 rows\n",
      "dropped \u001b[31m1600\u001b[0m / 1600 rows\n",
      "\u001b[1mModel:\u001b[0m \u001b[36mLinearRegression()\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('knn_3_1600',)\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m25\u001b[0m\n",
      "X has 24 features, but LinearRegression is expecting 11 features as input.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Outlier Detection\n",
    "    outlier_dict_all = {}\n",
    "\n",
    "    if OUTLIER99 == True:\n",
    "        print(\"outlier_99\")\n",
    "        outlier_list_99 = get99(df) #TODO Mean for price for trainingsdata\n",
    "        df = drop99_all(df, outlier_list_99 )\n",
    "        #outlier_dict_all[\"99_mean\"] = outlier_list_99\n",
    "        #outlier_dict_all[\"99_drop\"] = outlier_list_99\n",
    "        print(\"done\\n\")\n",
    "\n",
    "\n",
    "    print('done \\n\\nstarting knn')\n",
    "    for k in OUTLIER_KNN[\"K\"]:\n",
    "        for o in OUTLIER_KNN[\"X\"]:\n",
    "            print(k, o)\n",
    "            outlier_list_knn = outliers_knn(df, k, o, SPLIT_SIZE)\n",
    "            outlier_dict_all[\"knn_\"+str(k)+\"_\"+str(o)] = outlier_list_knn\n",
    "\n",
    "    ''''''\n",
    "    outlier_lists_all = list(outlier_dict_all.values())\n",
    "    outlier_lists_keys = list(outlier_dict_all.keys())\n",
    "    combination_list = []\n",
    "    for i, combo in enumerate(getCombinations(outlier_lists_keys), 1):\n",
    "        if not i == 1: #emtpy tuple\n",
    "            combination_list.append(combo)\n",
    "            # print('combo #{}: {}'.format(i, combo))\n",
    "    #print(\"...\")\n",
    "    #for c in combination_list[10:]:\n",
    "        #print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "    #print(bold(len(combination_list)), \" total Combinations\")\n",
    "\n",
    "    model_obj_list = []\n",
    "    for i, c in enumerate(combination_list):\n",
    "        #print(f'\\n{bold(i)}: {blue(c)}')\n",
    "        outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "        try: \n",
    "            if \"99_mean\" in c:\n",
    "                X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"both\", outlier_list_99)\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "\n",
    "            #TODO Regressionmodels\n",
    "            model = LinearRegression()\n",
    "            obj = Model(model, (X_train, X_test, y_train, y_test), c, df, df.columns.to_list())\n",
    "            model_obj_list.append(obj)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(bold(\"Error\"), red(e))\n",
    "\n",
    "    #Summary\n",
    "    df_summary = pd.DataFrame(columns=['combo', 'mae', 'score'])\n",
    "    for o in model_obj_list:\n",
    "        #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "        o.train()\n",
    "        mae, score = o.summary()\n",
    "        comb = o.get_comb()\n",
    "        row = {'combo': comb, 'mae': mae, 'score': score}\n",
    "        df_summary = df_summary.append(row, ignore_index=True)\n",
    "\n",
    "    df_summary.sort_values(\"mae\").head()\n",
    "\n",
    "    ##row\n",
    "    mae_best = df_summary[df_summary.mae==df_summary.mae.min()]\n",
    "    score_best = df_summary[df_summary.score==df_summary.score.max()]\n",
    "    best_model_obj = getBestModel(model_obj_list, df_summary, mae_best.index[0])\n",
    "    print(best_model_obj)\n",
    "    #print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "    model_obj_list_best = [best_model_obj]\n",
    "    df_feature_reduction = best_model_obj.get_df().head()\n",
    "\n",
    "    # print(df_feature_reduction)\n",
    "\n",
    "    ###Feature\n",
    "    for threshold in FEATURE_SEL_CORR[\"THRESHOLD_CORR\"]:\n",
    "        #print(threshold, type(threshold))\n",
    "        try: \n",
    "            rel_features = getRelFeatures(df_feature_reduction, threshold)\n",
    "            #print(len(rel_features), rel_features)\n",
    "            df_feature_reduction = df_feature_reduction[rel_features]\n",
    "            X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "            best_model_obj_new = Model(best_model_obj.get_model(), (X_train, X_test, y_train, y_test), best_model_obj.get_comb() , df_feature_reduction,df_feature_reduction.columns.to_list())\n",
    "            # best_model_obj_new.train()\n",
    "            model_obj_list_best.append(best_model_obj_new)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(bold(\"Error\"), red(e))\n",
    "    #print(model_obj_list_best)\n",
    "\n",
    "    #Summary\n",
    "    df_summary_best = pd.DataFrame(columns=['combo', 'mae', 'score', 'features'])\n",
    "    for o in model_obj_list_best:\n",
    "        #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "        o.train()\n",
    "        mae, score = o.summary()\n",
    "        comb = o.get_comb()\n",
    "        features = o.get_df().columns.to_list()\n",
    "        features.remove(\"price\")\n",
    "        row = {'combo': comb, 'mae': mae, 'score': score, 'features': features}\n",
    "        df_summary_best = df_summary_best.append(row, ignore_index=True)\n",
    "\n",
    "    #df_summary_best.sort_values(\"mae\")\n",
    "\n",
    "    #row\n",
    "    mae_best = df_summary_best[df_summary_best.mae==df_summary_best.mae.min()]\n",
    "    score_best = df_summary_best[df_summary_best.score==df_summary_best.score.max()]\n",
    "    best_model_obj = getBestModel(model_obj_list_best, df_summary_best, mae_best.index[0])\n",
    "    print(best_model_obj)\n",
    "    print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "    lines = f'{df_summary_best[\"combo\"][0]} - {df_summary_best[\"mae\"][0]} - {len(df_summary_best[\"features\"][0])} ' \n",
    "\n",
    "    with open('parameter_search.txt', 'a+') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "        f.write('\\n')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB_SCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier_99\n",
      "done\n",
      "\n",
      "done \n",
      "\n",
      "starting db_scan\n",
      "3 500 0.5 6.6\n",
      "3 1500 0.5 6.6\n",
      "4 500 0.5 6.6\n",
      "4 1500 0.5 6.6\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "dropped \u001b[31m1397\u001b[0m / 1397 rows\n",
      "\u001b[1mModel:\u001b[0m \u001b[36mLinearRegression()\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_3_500_0.5_6.6',)\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m25\u001b[0m\n",
      "\u001b[1mError\u001b[0m \u001b[31m__init__() missing 1 required positional argument: 'features'\u001b[0m\n",
      "\u001b[1mError\u001b[0m \u001b[31m__init__() missing 1 required positional argument: 'features'\u001b[0m\n",
      "\u001b[1mError\u001b[0m \u001b[31m__init__() missing 1 required positional argument: 'features'\u001b[0m\n",
      "\u001b[1mModel:\u001b[0m \u001b[36mLinearRegression()\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_3_500_0.5_6.6',)\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m25\u001b[0m\n",
      "\u001b[1mLowest mae:\u001b[0m                       combo        mae     score  \\\n",
      "0  (db_scan_3_500_0.5_6.6,)  161024.91  0.468065   \n",
      "\n",
      "                                            features  \n",
      "0  [id, date, bedrooms, bathrooms, sqft_living, s...  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Outlier Detection\n",
    "    outlier_dict_all = {}\n",
    "\n",
    "    if OUTLIER99 == True:\n",
    "        print(\"outlier_99\")\n",
    "        outlier_list_99 = get99(df) #TODO Mean for price for trainingsdata\n",
    "        df = drop99_all(df, outlier_list_99 )\n",
    "        #outlier_dict_all[\"99_mean\"] = outlier_list_99\n",
    "        #outlier_dict_all[\"99_drop\"] = outlier_list_99\n",
    "        print(\"done\\n\")\n",
    "\n",
    "\n",
    "    print('done \\n\\nstarting db_scan')\n",
    "    for k in OUTLIER_DBSCAN[\"K\"]:\n",
    "        for o in OUTLIER_DBSCAN[\"X\"]:\n",
    "            for e in OUTLIER_DBSCAN[\"EPS\"]:\n",
    "                for m in OUTLIER_DBSCAN[\"MIN_SAMPLES\"]:\n",
    "                    print(k, o, e, m)\n",
    "                    outlier_list_dbscan = outliers_dbscan(df, k, o, e, m, SPLIT_SIZE)\n",
    "                    outlier_dict_all[\"db_scan_\"+str(k)+\"_\"+str(o)+\"_\"+str(e)+\"_\"+str(m)] = outlier_list_dbscan\n",
    "\n",
    "\n",
    "    ''''''\n",
    "    outlier_lists_all = list(outlier_dict_all.values())\n",
    "    outlier_lists_keys = list(outlier_dict_all.keys())\n",
    "    combination_list = []\n",
    "    for i, combo in enumerate(getCombinations(outlier_lists_keys), 1):\n",
    "        if not i == 1: #emtpy tuple\n",
    "            combination_list.append(combo)\n",
    "            # print('combo #{}: {}'.format(i, combo))\n",
    "    #print(\"...\")\n",
    "    #for c in combination_list[10:]:\n",
    "        #print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "    #print(bold(len(combination_list)), \" total Combinations\")\n",
    "\n",
    "    model_obj_list = []\n",
    "    for i, c in enumerate(combination_list):\n",
    "        #print(f'\\n{bold(i)}: {blue(c)}')\n",
    "        outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "        try: \n",
    "            if \"99_mean\" in c:\n",
    "                X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"both\", outlier_list_99)\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "\n",
    "            #TODO Regressionmodels\n",
    "            model = LinearRegression()\n",
    "            obj = Model(model, (X_train, X_test, y_train, y_test), c, df, df.columns.to_list())\n",
    "            model_obj_list.append(obj)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(bold(\"Error\"), red(e))\n",
    "\n",
    "    #Summary\n",
    "    df_summary = pd.DataFrame(columns=['combo', 'mae', 'score'])\n",
    "    for o in model_obj_list:\n",
    "        #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "        o.train()\n",
    "        mae, score = o.summary()\n",
    "        comb = o.get_comb()\n",
    "        row = {'combo': comb, 'mae': mae, 'score': score}\n",
    "        df_summary = df_summary.append(row, ignore_index=True)\n",
    "\n",
    "    df_summary.sort_values(\"mae\").head()\n",
    "\n",
    "    ##row\n",
    "    mae_best = df_summary[df_summary.mae==df_summary.mae.min()]\n",
    "    score_best = df_summary[df_summary.score==df_summary.score.max()]\n",
    "    best_model_obj = getBestModel(model_obj_list, df_summary, mae_best.index[0])\n",
    "    print(best_model_obj)\n",
    "    #print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "    model_obj_list_best = [best_model_obj]\n",
    "    df_feature_reduction = best_model_obj.get_df().head()\n",
    "\n",
    "    # print(df_feature_reduction)\n",
    "\n",
    "    ###Feature\n",
    "    for threshold in FEATURE_SEL_CORR[\"THRESHOLD_CORR\"]:\n",
    "        #print(threshold, type(threshold))\n",
    "        try: \n",
    "            rel_features = getRelFeatures(df_feature_reduction, threshold)\n",
    "            #print(len(rel_features), rel_features)\n",
    "            df_feature_reduction = df_feature_reduction[rel_features]\n",
    "            X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "            best_model_obj_new = Model(best_model_obj.get_model(), (X_train, X_test, y_train, y_test), best_model_obj.get_comb() , df_feature_reduction)\n",
    "            # best_model_obj_new.train()\n",
    "            model_obj_list_best.append(best_model_obj_new)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(bold(\"Error\"), red(e))\n",
    "    #print(model_obj_list_best)\n",
    "\n",
    "    #Summary\n",
    "    df_summary_best = pd.DataFrame(columns=['combo', 'mae', 'score', 'features'])\n",
    "    for o in model_obj_list_best:\n",
    "        #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "        o.train()\n",
    "        mae, score = o.summary()\n",
    "        comb = o.get_comb()\n",
    "        features = o.get_df().columns.to_list()\n",
    "        features.remove(\"price\")\n",
    "        row = {'combo': comb, 'mae': mae, 'score': score, 'features': features}\n",
    "        df_summary_best = df_summary_best.append(row, ignore_index=True)\n",
    "\n",
    "    #df_summary_best.sort_values(\"mae\")\n",
    "\n",
    "    #row\n",
    "    mae_best = df_summary_best[df_summary_best.mae==df_summary_best.mae.min()]\n",
    "    score_best = df_summary_best[df_summary_best.score==df_summary_best.score.max()]\n",
    "    best_model_obj = getBestModel(model_obj_list_best, df_summary_best, mae_best.index[0])\n",
    "    print(best_model_obj)\n",
    "    print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "    lines = f'{df_summary_best[\"combo\"][0]} - {df_summary_best[\"mae\"][0]} - {len(df_summary_best[\"features\"][0])} ' \n",
    "\n",
    "    with open('parameter_search.txt', 'a+') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "        f.write('\\n')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier_99\n",
      "done\n",
      "\n",
      "done \n",
      "\n",
      "starting noise\n",
      "2.5 3 5\n",
      "Expected cv as an integer, cross-validation object (from sklearn.model_selection) or an iterable. Got 2.5.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Outlier Detection\n",
    "    outlier_dict_all = {}\n",
    "\n",
    "    if OUTLIER99 == True:\n",
    "        print(\"outlier_99\")\n",
    "        outlier_list_99 = get99(df) #TODO Mean for price for trainingsdata\n",
    "        df = drop99_all(df, outlier_list_99 )\n",
    "        #outlier_dict_all[\"99_mean\"] = outlier_list_99\n",
    "        #outlier_dict_all[\"99_drop\"] = outlier_list_99\n",
    "        print(\"done\\n\")\n",
    "\n",
    "    print('done \\n\\nstarting noise')\n",
    "    for cv in OUTLIER_NOISE[\"CV\"]:\n",
    "        for d in OUTLIER_NOISE[\"DEPTH\"]:\n",
    "            for m in OUTLIER_NOISE[\"MULTI\"]:\n",
    "                print(cv, d, m)\n",
    "                outlier_list_noise = getNoise(df, cv, d, m)\n",
    "                outlier_dict_all[\"noise_\"+str(cv)+\"_\"+str(d)+\"_\"+str(m)] = outlier_list_noise\n",
    "\n",
    "    print('done')\n",
    "\n",
    "\n",
    "    ''''''\n",
    "    outlier_lists_all = list(outlier_dict_all.values())\n",
    "    outlier_lists_keys = list(outlier_dict_all.keys())\n",
    "    combination_list = []\n",
    "    for i, combo in enumerate(getCombinations(outlier_lists_keys), 1):\n",
    "        if not i == 1: #emtpy tuple\n",
    "            combination_list.append(combo)\n",
    "            # print('combo #{}: {}'.format(i, combo))\n",
    "    #print(\"...\")\n",
    "    #for c in combination_list[10:]:\n",
    "        #print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "    #print(bold(len(combination_list)), \" total Combinations\")\n",
    "\n",
    "    model_obj_list = []\n",
    "    for i, c in enumerate(combination_list):\n",
    "        #print(f'\\n{bold(i)}: {blue(c)}')\n",
    "        outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "        try: \n",
    "            if \"99_mean\" in c:\n",
    "                X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"both\", outlier_list_99)\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "\n",
    "            #TODO Regressionmodels\n",
    "            model = LinearRegression()\n",
    "            obj = Model(model, (X_train, X_test, y_train, y_test), c, df, df.columns.to_list())\n",
    "            model_obj_list.append(obj)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(bold(\"Error\"), red(e))\n",
    "\n",
    "    #Summary\n",
    "    df_summary = pd.DataFrame(columns=['combo', 'mae', 'score'])\n",
    "    for o in model_obj_list:\n",
    "        #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "        o.train()\n",
    "        mae, score = o.summary()\n",
    "        comb = o.get_comb()\n",
    "        row = {'combo': comb, 'mae': mae, 'score': score}\n",
    "        df_summary = df_summary.append(row, ignore_index=True)\n",
    "\n",
    "    df_summary.sort_values(\"mae\").head()\n",
    "\n",
    "    ##row\n",
    "    mae_best = df_summary[df_summary.mae==df_summary.mae.min()]\n",
    "    score_best = df_summary[df_summary.score==df_summary.score.max()]\n",
    "    best_model_obj = getBestModel(model_obj_list, df_summary, mae_best.index[0])\n",
    "    print(best_model_obj)\n",
    "    #print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "    model_obj_list_best = [best_model_obj]\n",
    "    df_feature_reduction = best_model_obj.get_df().head()\n",
    "\n",
    "    # print(df_feature_reduction)\n",
    "\n",
    "    ###Feature\n",
    "    for threshold in FEATURE_SEL_CORR[\"THRESHOLD_CORR\"]:\n",
    "        #print(threshold, type(threshold))\n",
    "        try: \n",
    "            rel_features = getRelFeatures(df_feature_reduction, threshold)\n",
    "            #print(len(rel_features), rel_features)\n",
    "            df_feature_reduction = df_feature_reduction[rel_features]\n",
    "            X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "            best_model_obj_new = Model(best_model_obj.get_model(), (X_train, X_test, y_train, y_test), best_model_obj.get_comb() , df_feature_reduction, df_feature_reduction.columns.to_list() )\n",
    "            # best_model_obj_new.train()\n",
    "            model_obj_list_best.append(best_model_obj_new)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(bold(\"Error\"), red(e))\n",
    "    #print(model_obj_list_best)\n",
    "\n",
    "    #Summary\n",
    "    df_summary_best = pd.DataFrame(columns=['combo', 'mae', 'score', 'features'])\n",
    "    for o in model_obj_list_best:\n",
    "        #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "        o.train()\n",
    "        mae, score = o.summary()\n",
    "        comb = o.get_comb()\n",
    "        features = o.get_df().columns.to_list()\n",
    "        features.remove(\"price\")\n",
    "        row = {'combo': comb, 'mae': mae, 'score': score, 'features': features}\n",
    "        df_summary_best = df_summary_best.append(row, ignore_index=True)\n",
    "\n",
    "    #df_summary_best.sort_values(\"mae\")\n",
    "\n",
    "    #row\n",
    "    mae_best = df_summary_best[df_summary_best.mae==df_summary_best.mae.min()]\n",
    "    score_best = df_summary_best[df_summary_best.score==df_summary_best.score.max()]\n",
    "    best_model_obj = getBestModel(model_obj_list_best, df_summary_best, mae_best.index[0])\n",
    "    print(best_model_obj)\n",
    "    print(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "\n",
    "    lines = f'{df_summary_best[\"combo\"][0]} - {df_summary_best[\"mae\"][0]} - {len(df_summary_best[\"features\"][0])} ' \n",
    "\n",
    "    #import os.path\n",
    "    #file_exists = os.path.exists('parameter_search.txt')\n",
    "    # if file_exists == False:\n",
    "    #     with open('parameter_search.txt', 'w') as f:\n",
    "    #         f.write('Create a new text file!')\n",
    "\n",
    "    with open('parameter_search.txt', 'a+') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "        f.write('\\n')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49d1cf207c92197553c1326cc52484d1ee2809997f5109c15474876a3e083b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

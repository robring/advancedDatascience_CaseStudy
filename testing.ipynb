{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import Model, get99, splitData, dropMissingValues, z_score, outliers_knn, outliers_dbscan, getNoise, getRelFeatures, drop_features, getCombinations, get_unique_list, bold, blue, red, green, getBestModel, np_to_df, df_to_np, drop99_all, z_score_individual, train_test_to_df\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file\n",
    "f = open ('data/json/input.json', \"r\")\n",
    "  # Reading from file\n",
    "PARAMETERS = json.loads(f.read())\n",
    "\n",
    "SPLIT_SIZE = PARAMETERS[\"SPLIT_SIZE\"]\n",
    "\n",
    "OUTLIER99 = PARAMETERS[\"OUTLIER99\"] \n",
    "OUTLIER_ZSCORE = {\"STD\" : PARAMETERS[\"OUTLIER_ZSCORE\"][\"STD\"]}\n",
    "OUTLIER_ZSCORE_IND = PARAMETERS[\"OUTLIER_ZSCORE_IND\"]\n",
    "OUTLIER_KNN = {\"K\": PARAMETERS[\"OUTLIER_KNN\"][\"K\"], \"X\": PARAMETERS[\"OUTLIER_KNN\"][\"X\"]}\n",
    "OUTLIER_DBSCAN = {\"K\": PARAMETERS[\"OUTLIER_DBSCAN\"][\"K\"], \"X\": PARAMETERS[\"OUTLIER_DBSCAN\"][\"X\"], \"EPS\": PARAMETERS[\"OUTLIER_DBSCAN\"][\"EPS\"], \"MIN_SAMPLES\":  PARAMETERS[\"OUTLIER_DBSCAN\"][\"MIN_SAMPLES\"]}\n",
    "OUTLIER_NOISE = {\"CV\": PARAMETERS[\"OUTLIER_NOISE\"][\"CV\"]}\n",
    "\n",
    "FEATURE_SEL_CORR = {\"THRESHOLD_CORR\": PARAMETERS[\"FEATURE_SEL_CORR\"][\"THRESHOLD\"]}\n",
    "\n",
    "f.close()\n",
    "\n",
    "#TODO FEATURE\n",
    "#TODO Regressionmodels\n",
    "#TODO TESTDATA --> path to csv-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get raw Data\n",
    "df = pd.read_csv(\"data/csv/house_data_training.csv\", sep=';') \n",
    "# remove unnamed column\n",
    "df = df.iloc[:, 1:]\n",
    "#Transform string to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "maeList = []#for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropMissingValues(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection\n",
    "outlier_dict_all = {}\n",
    "\n",
    "if OUTLIER99 == True:\n",
    "    print(\"outlier_99\")\n",
    "    outlier_list_99 = get99(df) #TODO Mean for price for trainingsdata\n",
    "    df = drop99_all(df, outlier_list_99 )\n",
    "    #outlier_dict_all[\"99_mean\"] = outlier_list_99\n",
    "    #outlier_dict_all[\"99_drop\"] = outlier_list_99\n",
    "    print(green('done'), \"\\n\")\n",
    "\n",
    "print('starting z_score')\n",
    "for p in OUTLIER_ZSCORE[\"STD\"]:\n",
    "    print(p)\n",
    "    outlier_list_z_score = z_score(df, p)\n",
    "    outlier_dict_all[\"z_score_\"+str(p)] = outlier_list_z_score\n",
    "\n",
    "if OUTLIER_ZSCORE_IND == True:\n",
    "    outlier_list_z_score_ind = z_score_individual(df)\n",
    "\n",
    "print(green('done'), '\\n\\nstarting knn')\n",
    "for k in OUTLIER_KNN[\"K\"]:\n",
    "    for o in OUTLIER_KNN[\"X\"]:\n",
    "        print(k, o)\n",
    "        outlier_list_knn = outliers_knn(df, k, o, SPLIT_SIZE)\n",
    "        outlier_dict_all[\"knn_\"+str(k)+\"_\"+str(o)] = outlier_list_knn\n",
    "\n",
    "print(green('done'), '\\n\\nstarting db_scan')\n",
    "for k in OUTLIER_DBSCAN[\"K\"]:\n",
    "    for o in OUTLIER_DBSCAN[\"X\"]:\n",
    "        for e in OUTLIER_DBSCAN[\"EPS\"]:\n",
    "            for m in OUTLIER_DBSCAN[\"MIN_SAMPLES\"]:\n",
    "                print(k, o, e, m)\n",
    "                outlier_list_dbscan = outliers_dbscan(df, k, o, e, m, SPLIT_SIZE)\n",
    "                outlier_dict_all[\"db_scan\"] = outlier_list_dbscan\n",
    "\n",
    "print(green('done'), '\\n\\nstarting noise')\n",
    "for cv in OUTLIER_NOISE[\"CV\"]:\n",
    "        print(cv)\n",
    "        outlier_list_noise = getNoise(df, cv)\n",
    "        outlier_dict_all[\"noise_\"+str(cv)] = outlier_list_noise\n",
    "print(green('done'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_lists_all = list(outlier_dict_all.values())\n",
    "outlier_lists_keys = list(outlier_dict_all.keys())\n",
    "combination_list = []\n",
    "for i, combo in enumerate(getCombinations(outlier_lists_keys), 1):\n",
    "    if not i == 1: #emtpy tuple\n",
    "        combination_list.append(combo)\n",
    "        # print('combo #{}: {}'.format(i, combo))\n",
    "print(\"...\")\n",
    "for c in combination_list[10:]:\n",
    "    print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "print(bold(len(combination_list)), \" total Combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj_list = []\n",
    "for i, c in enumerate(combination_list):\n",
    "    print(f'\\n{bold(i)}: {blue(c)}')\n",
    "    outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "    try: \n",
    "        \n",
    "        # if \"99_mean\" in c:\n",
    "        #     X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"both\", outlier_list_99)\n",
    "        # else:\n",
    "        #     X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "        #df_price_rem = df.drop(columns=[\"price\"])\n",
    "        # print(df_price_rem[:2])\n",
    "        #print(df[:1])\n",
    "        X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\") #TODO drop entfernen\n",
    "        #print(\"test\")\n",
    "        #df_linear = train_test_to_df(X_train, X_test, y_train, y_test, df.columns.to_list())\n",
    "        #print(df_linear[:1])\n",
    "        \n",
    "        #TODO Regressionmodels\n",
    "        model = LinearRegression()\n",
    "        obj = Model(model, (X_train, X_test, y_train, y_test), c, df, df.columns.to_list())\n",
    "        model_obj_list.append(obj)\n",
    "\n",
    "        # ''''''     \n",
    "        # df_lasso = train_test_to_df(X_train, X_test, y_train, y_test, df.columns.to_list())\n",
    "        # #print(df_lasso[:1])\n",
    "        # # X = np.append(X_train, X_test, axis=0)\n",
    "        # # y = np.append(y_train, y_test.reshape(len(y_test), 1), axis=0)\n",
    "        # # X_y = np.append(X, y, axis=1)\n",
    "        # # features = df.columns.to_list()\n",
    "        # # df_adsa = pd.DataFrame(X_y, columns=features)\n",
    "\n",
    "        # X_l, y_l = df_lasso.drop(columns=[\"price\", \"date\", \"id\"]), df_lasso[\"price\"]\n",
    "        # scaler = StandardScaler().fit(X_l)\n",
    "        # X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_l, y_l, test_size = SPLIT_SIZE, random_state=1) #TODO \n",
    "        # #rint(X_train_l)\n",
    "        # X_train_l = scaler.transform(X_train_l)\n",
    "        # X_test_l = scaler.transform(X_test_l)\n",
    "        # reg = Lasso(alpha=1)\n",
    "        # obj_l = Model(reg, (X_train_l, X_test_l, y_train_l, y_test_l), c, df_lasso, X_l.columns.to_list())\n",
    "        # model_obj_list.append(obj_l)\n",
    "        # ''''''\n",
    "    except Exception as e:\n",
    "        print(bold(\"Error\"), red(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_obj_list = []\n",
    "for i, c in enumerate(combination_list):\n",
    "    print(f'\\n{bold(i)}: {blue(c)}')\n",
    "    outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "    try: \n",
    "        X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "        df_lasso = train_test_to_df(X_train, X_test, y_train, y_test, df.columns.to_list())\n",
    "        #print(df_lasso[:1])\n",
    "        # X = np.append(X_train, X_test, axis=0)\n",
    "        # y = np.append(y_train, y_test.reshape(len(y_test), 1), axis=0)\n",
    "        # X_y = np.append(X, y, axis=1)\n",
    "        # features = df.columns.to_list()\n",
    "        # df_adsa = pd.DataFrame(X_y, columns=features)\n",
    "\n",
    "        X_l, y_l = df_lasso.drop(columns=[\"price\", \"date\", \"id\"]), df_lasso[\"price\"]\n",
    "        scaler = StandardScaler().fit(X_l)\n",
    "        X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_l, y_l, test_size = SPLIT_SIZE, random_state=1) #TODO \n",
    "        #rint(X_train_l)\n",
    "        X_train_l = scaler.transform(X_train_l)\n",
    "        X_test_l = scaler.transform(X_test_l)\n",
    "        reg = Lasso(alpha=1)\n",
    "        obj_l = Model(reg, (X_train_l, X_test_l, y_train_l, y_test_l), c, df_lasso, X_l.columns.to_list())\n",
    "        model_obj_list.append(obj_l)\n",
    "        ''''''\n",
    "    except Exception as e:\n",
    "        print(bold(\"Error\"), red(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getDF(self):\n",
    "#     X_train, X_test, y_train, y_test = self.get_data()\n",
    "#     print(len(y_test))\n",
    "#     #print(y_train.shape, y_test.reshape(len(y_test), 1).shape)\n",
    "#     X = np.append(X_train, X_test, axis=0)\n",
    "#     y = np.append(y_train, y_test.reshape(len(y_test), 1), axis=0)\n",
    "#     X_y = np.append(X, y, axis=1)\n",
    "#     features = df.columns.to_list()\n",
    "#     features.remove(\"price\")\n",
    "#     df = pd.DataFrame(X_y, columns=features)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>combo</th>\n",
       "      <th>mae</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, knn_3_200, db_scan, noise_5)</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, db_scan, noise_5)</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, knn_3_200, db_scan)</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan, noise_5)</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, db_scan)</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(knn_3_200, db_scan, noise_5)</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(knn_3_200, db_scan)</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan,)</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, knn_3_200, noise_5)</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(knn_3_200, noise_5)</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1,)</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, knn_3_200)</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(knn_3_200,)</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, noise_5)</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.00068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(noise_5,)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, knn_3_200, db_scan, noise_5)</td>\n",
       "      <td>161768.15</td>\n",
       "      <td>0.449157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, db_scan, noise_5)</td>\n",
       "      <td>161768.15</td>\n",
       "      <td>0.449157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, knn_3_200, db_scan)</td>\n",
       "      <td>161773.99</td>\n",
       "      <td>0.449083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, db_scan)</td>\n",
       "      <td>161773.99</td>\n",
       "      <td>0.449083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(db_scan, noise_5)</td>\n",
       "      <td>161776.63</td>\n",
       "      <td>0.44903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(knn_3_200, db_scan, noise_5)</td>\n",
       "      <td>161776.63</td>\n",
       "      <td>0.44903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(knn_3_200, db_scan)</td>\n",
       "      <td>161782.62</td>\n",
       "      <td>0.448957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(db_scan,)</td>\n",
       "      <td>161782.62</td>\n",
       "      <td>0.448957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, knn_3_200)</td>\n",
       "      <td>162584.63</td>\n",
       "      <td>0.481578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(knn_3_200,)</td>\n",
       "      <td>162593.92</td>\n",
       "      <td>0.481691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, knn_3_200, noise_5)</td>\n",
       "      <td>162601.8</td>\n",
       "      <td>0.481608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(knn_3_200, noise_5)</td>\n",
       "      <td>162611.04</td>\n",
       "      <td>0.481721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1,)</td>\n",
       "      <td>165149.5</td>\n",
       "      <td>0.525593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, noise_5)</td>\n",
       "      <td>165189.16</td>\n",
       "      <td>0.525594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(noise_5,)</td>\n",
       "      <td>165189.86</td>\n",
       "      <td>0.525635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model                                        combo  \\\n",
       "29      Lasso(alpha=1)  (z_score_10.1, knn_3_200, db_scan, noise_5)   \n",
       "27      Lasso(alpha=1)             (z_score_10.1, db_scan, noise_5)   \n",
       "25      Lasso(alpha=1)           (z_score_10.1, knn_3_200, db_scan)   \n",
       "24      Lasso(alpha=1)                           (db_scan, noise_5)   \n",
       "20      Lasso(alpha=1)                      (z_score_10.1, db_scan)   \n",
       "28      Lasso(alpha=1)                (knn_3_200, db_scan, noise_5)   \n",
       "22      Lasso(alpha=1)                         (knn_3_200, db_scan)   \n",
       "17      Lasso(alpha=1)                                   (db_scan,)   \n",
       "26      Lasso(alpha=1)           (z_score_10.1, knn_3_200, noise_5)   \n",
       "23      Lasso(alpha=1)                         (knn_3_200, noise_5)   \n",
       "15      Lasso(alpha=1)                              (z_score_10.1,)   \n",
       "19      Lasso(alpha=1)                    (z_score_10.1, knn_3_200)   \n",
       "16      Lasso(alpha=1)                                 (knn_3_200,)   \n",
       "21      Lasso(alpha=1)                      (z_score_10.1, noise_5)   \n",
       "18      Lasso(alpha=1)                                   (noise_5,)   \n",
       "14  LinearRegression()  (z_score_10.1, knn_3_200, db_scan, noise_5)   \n",
       "12  LinearRegression()             (z_score_10.1, db_scan, noise_5)   \n",
       "10  LinearRegression()           (z_score_10.1, knn_3_200, db_scan)   \n",
       "5   LinearRegression()                      (z_score_10.1, db_scan)   \n",
       "9   LinearRegression()                           (db_scan, noise_5)   \n",
       "13  LinearRegression()                (knn_3_200, db_scan, noise_5)   \n",
       "7   LinearRegression()                         (knn_3_200, db_scan)   \n",
       "2   LinearRegression()                                   (db_scan,)   \n",
       "4   LinearRegression()                    (z_score_10.1, knn_3_200)   \n",
       "1   LinearRegression()                                 (knn_3_200,)   \n",
       "11  LinearRegression()           (z_score_10.1, knn_3_200, noise_5)   \n",
       "8   LinearRegression()                         (knn_3_200, noise_5)   \n",
       "0   LinearRegression()                              (z_score_10.1,)   \n",
       "6   LinearRegression()                      (z_score_10.1, noise_5)   \n",
       "3   LinearRegression()                                   (noise_5,)   \n",
       "\n",
       "          mae     score  \n",
       "29       0.67 -0.001289  \n",
       "27       0.67 -0.001289  \n",
       "25       0.67 -0.000193  \n",
       "24       0.67 -0.001379  \n",
       "20       0.67 -0.000193  \n",
       "28       0.67 -0.001379  \n",
       "22       0.68 -0.000687  \n",
       "17       0.68 -0.000687  \n",
       "26       0.72 -0.000212  \n",
       "23       0.72  -0.00009  \n",
       "15       0.72 -0.000314  \n",
       "19       0.73 -0.000166  \n",
       "16       0.73 -0.000157  \n",
       "21       0.74  -0.00068  \n",
       "18       0.75 -0.000006  \n",
       "14  161768.15  0.449157  \n",
       "12  161768.15  0.449157  \n",
       "10  161773.99  0.449083  \n",
       "5   161773.99  0.449083  \n",
       "9   161776.63   0.44903  \n",
       "13  161776.63   0.44903  \n",
       "7   161782.62  0.448957  \n",
       "2   161782.62  0.448957  \n",
       "4   162584.63  0.481578  \n",
       "1   162593.92  0.481691  \n",
       "11   162601.8  0.481608  \n",
       "8   162611.04  0.481721  \n",
       "0    165149.5  0.525593  \n",
       "6   165189.16  0.525594  \n",
       "3   165189.86  0.525635  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary\n",
    "df_summary = pd.DataFrame(columns=['model', 'combo', 'mae', 'score'])\n",
    "for o in model_obj_list:\n",
    "    #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "    o.train()\n",
    "    mae, score = o.summary()\n",
    "    comb = o.get_comb()\n",
    "    row = {'model': o.get_model(), 'combo': comb, 'mae': mae, 'score': score}\n",
    "    df_summary = df_summary.append(row, ignore_index=True)\n",
    "\n",
    "df_summary.sort_values(\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel:\u001b[0m \u001b[36mLinearRegression()\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('knn_3_200',)\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m24\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 24 features, but Lasso is expecting 22 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12748/3247864079.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlassotest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(reg.score(X_test, y_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mae\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \"\"\"\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 24 features, but Lasso is expecting 22 features as input."
     ]
    }
   ],
   "source": [
    "print(model_obj_list[1])\n",
    "lassotest = model_obj_list[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = lassotest.get_data()\n",
    "lassotest.get_model().fit(X_train, y_train)\n",
    "#print(reg.score(X_test, y_test))\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"mae\", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row\n",
    "mae_best = df_summary[df_summary.mae==df_summary.mae.min()]\n",
    "#print(mae_best)\n",
    "#score_best = df_summary[df_summary.score==df_summary.score.max()]\n",
    "best_model_obj = getBestModel(model_obj_list, df_summary, mae_best.index[0])\n",
    "print(best_model_obj)\n",
    "#rint(f'{bold(\"Lowest mae:\")} {mae_best}')\n",
    "#model_obj_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj_list_best = [best_model_obj]\n",
    "X_train, X_test, y_train, y_test = best_model_obj.get_data()\n",
    "\n",
    "df_feature_reduction = train_test_to_df(X_train, X_test, y_train, y_test, best_model_obj.get_features())\n",
    "print(df_feature_reduction.columns)\n",
    "#print(df_feature_reduction)\n",
    "\n",
    "for threshold in FEATURE_SEL_CORR[\"THRESHOLD_CORR\"]:\n",
    "    #print(threshold, type(threshold))\n",
    "    try: \n",
    "        rel_features = getRelFeatures(df_feature_reduction, threshold)\n",
    "        print(len(rel_features), rel_features)\n",
    "        df_feature_reduction = df_feature_reduction[rel_features]\n",
    "        X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "        best_model_obj_new = Model(best_model_obj.get_model(), (X_train, X_test, y_train, y_test), best_model_obj.get_comb() , df_feature_reduction)\n",
    "        model_obj_list_best.append(best_model_obj_new)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(bold(\"Error\"), red(e))\n",
    "print(model_obj_list_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary\n",
    "df_summary_best = pd.DataFrame(columns=['model', 'combo', 'mae', 'score', 'features'])\n",
    "for o in model_obj_list_best:\n",
    "    #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "    o.train()\n",
    "    mae, score = o.summary()\n",
    "    comb = o.get_comb()\n",
    "    features = o.get_df().columns.to_list()\n",
    "    if \"price\" in features:\n",
    "        features.remove(\"price\")\n",
    "    row = {'model': o.get_model(),'combo': comb, 'mae': mae, 'score': score, 'features': features}\n",
    "    df_summary_best = df_summary_best.append(row, ignore_index=True)\n",
    "\n",
    "df_summary_best.sort_values(\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row\n",
    "mae_best = df_summary_best[df_summary_best.mae==df_summary_best.mae.min()]\n",
    "#score_best = df_summary_best[df_summary_best.score==df_summary_best.score.max()]\n",
    "best_model_obj = getBestModel(model_obj_list_best, df_summary_best, mae_best.index[0])\n",
    "print(best_model_obj)\n",
    "print(f'{bold(\"Lowest mae:\")} {mae_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12748/1090043412.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mbest_model_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model_obj' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test =  best_model_obj.get_data()\n",
    "X = np.append(X_train, X_test, axis=0)\n",
    "y = np.append(y_train, y_test.reshape(len(y_test), 1), axis=0)\n",
    "X_y = np.append(X, y, axis=1)\n",
    "features = df.columns.to_list()\n",
    "df_adsa = pd.DataFrame(X_y, columns=features)\n",
    "\n",
    "df_adsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = ['bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'dis_super', 'view', 'condition',\n",
    "       'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
    "       'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'ahf1', 'ahf2',\n",
    "       'ahf3']\n",
    "from functions import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X, y = df_adsa.drop(columns=[\"price\", \"date\", \"id\"]), df_adsa[\"price\"]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = SPLIT_SIZE, random_state=1) \n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "reg = Lasso(alpha=1)\n",
    "reg.fit(X_train, y_train)\n",
    "print(reg.score(X_test, y_test))\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"dsds\", mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressionmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit_transform(best_model_obj_new.get_df())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluatuion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination_list = []\n",
    "# df_feature_reduction = best_model_obj.get_df()\n",
    "\n",
    "# for i, combo in enumerate(getCombinations(df_feature_reduction.columns.to_list()), 1):\n",
    "#     if not i == 1: #emtpy tuple\n",
    "#         combination_list.append(combo)\n",
    "#         # print('combo #{}: {}'.format(i, combo))\n",
    "# print(\"...\")\n",
    "# for c in combination_list[10:]:\n",
    "#     print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "# print(bold(len(combination_list)), \" total Combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_obj_list_best = []\n",
    "# df_feature_reduction = best_model_obj.get_df()\n",
    "# for i, c in enumerate(combination_list):\n",
    "#     print(f'\\n{bold(i)}: {blue(c)}')\n",
    "    \n",
    "#     try: \n",
    "#         X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "#         best_model_obj_copy = best_model_obj.copy()\n",
    "#         best_model_obj_copy.set_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#         model_obj_list_best.append(obj)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(bold(\"Error\"), red(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feature_reduction = best_model_obj.get_df()\n",
    "# getCombinations(df_feature_reduction.columns.to_list())\n",
    "\n",
    "# for feature in list(df_feature_reduction.columns.to_list()):\n",
    "#     df_feature_reduction.drop(columns=feature)\n",
    "#     X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "#     best_model_obj_copy = best_model_obj.copy()\n",
    "#     best_model_obj_copy.set_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Wrapper approaches\n",
    "# #Backward elimination using Recursive feature elimination¶\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn import feature_selection\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# x, y = df.drop(columns=[\"price\"]), df[\"price\"]\n",
    "# # x_y= np.concatenate((x.reshape(150,4),y.reshape(150,1)),1)\n",
    "# x_y= np.concatenate((x,y),1)\n",
    "# #print(x_y)\n",
    "# #print(iris.target_names)\n",
    "\n",
    "# #Create column list\n",
    "# df_columns=df.columns\n",
    "# # df_columns.append(\"Label\")\n",
    "# # #Create PANDAS data frame\n",
    "# # df = pd.DataFrame(x_y,columns=df_columns)\n",
    "# #Map label index to label name\n",
    "# df['price']=df['price'].map(lambda x: iris.target_names[int(x)])\n",
    "# print(\"\\nOriginal Iris Data Set:\")\n",
    "# print(df)\n",
    "\n",
    "# #Create the RFE object and rank features\n",
    "# num_features=2\n",
    "# svc = SVC(kernel=\"linear\", C=1)\n",
    "# rfe = feature_selection.RFE(estimator=svc, n_features_to_select=num_features, step=1)\n",
    "# rfe.fit(x, y)\n",
    "# #print(\"Selected features will have a ranking=1 and support=TRUE\")\n",
    "# #print(iris.feature_names,\" \",rfe.ranking_,\" \",rfe.support_)\n",
    "# #print(x.shape)\n",
    "\n",
    "# #extend column-mask by one column for the label (always true)\n",
    "# column_mask=np.append(rfe.support_,True)\n",
    "# #use list column_mask to mask df-columns list\n",
    "# reduced_iris_features = [df_columns[i] for i in range(len(df_columns)) if column_mask[i]]\n",
    "# print(\"Reduced_iris_features: \",reduced_iris_features)\n",
    "# # use reduced_iris_features to reduce the data frame\n",
    "# reduced_df=df[reduced_iris_features]\n",
    "\n",
    "# print(\"\\nIris Data Set reduced to \",num_features,\" features: \\n\",reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO sqft_living wenn price auffällig niedrig obwohl m² hoch clsuter\n",
    "#TODO PCA macht warscheinlich wenig sinn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49d1cf207c92197553c1326cc52484d1ee2809997f5109c15474876a3e083b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

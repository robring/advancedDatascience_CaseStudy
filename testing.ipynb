{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import Model, get99, splitData, dropMissingValues, z_score, outliers_knn, outliers_dbscan, getNoise, getRelFeatures, drop_features, getCombinations, get_unique_list, bold, blue, red, green, getBestModel, np_to_df, df_to_np, drop99_all, z_score_individual, train_test_to_df\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file\n",
    "f = open ('data/json/input.json', \"r\")\n",
    "  # Reading from file\n",
    "PARAMETERS = json.loads(f.read())\n",
    "\n",
    "SPLIT_SIZE = PARAMETERS[\"SPLIT_SIZE\"]\n",
    "\n",
    "OUTLIER99 = PARAMETERS[\"OUTLIER99\"] \n",
    "OUTLIER_ZSCORE = {\"STD\" : PARAMETERS[\"OUTLIER_ZSCORE\"][\"STD\"]}\n",
    "OUTLIER_ZSCORE_IND = PARAMETERS[\"OUTLIER_ZSCORE_IND\"]\n",
    "OUTLIER_KNN = {\"K\": PARAMETERS[\"OUTLIER_KNN\"][\"K\"], \"X\": PARAMETERS[\"OUTLIER_KNN\"][\"X\"]}\n",
    "OUTLIER_DBSCAN = {\"K\": PARAMETERS[\"OUTLIER_DBSCAN\"][\"K\"], \"X\": PARAMETERS[\"OUTLIER_DBSCAN\"][\"X\"], \"EPS\": PARAMETERS[\"OUTLIER_DBSCAN\"][\"EPS\"], \"MIN_SAMPLES\":  PARAMETERS[\"OUTLIER_DBSCAN\"][\"MIN_SAMPLES\"]}\n",
    "OUTLIER_NOISE = {\"CV\": PARAMETERS[\"OUTLIER_NOISE\"][\"CV\"], \"DEPTH\": PARAMETERS[\"OUTLIER_NOISE\"][\"DEPTH\"], \"MULTI\": PARAMETERS[\"OUTLIER_NOISE\"][\"MULTI\"] }\n",
    "\n",
    "FEATURE_SEL_CORR = {\"THRESHOLD_CORR\": PARAMETERS[\"FEATURE_SEL_CORR\"][\"THRESHOLD\"]}\n",
    "\n",
    "f.close()\n",
    "\n",
    "#TODO FEATURE\n",
    "#TODO Regressionmodels\n",
    "#TODO TESTDATA --> path to csv-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get raw Data\n",
    "df = pd.read_csv(\"data/csv/house_data_training.csv\", sep=';') \n",
    "# remove unnamed column\n",
    "df = df.iloc[:, 1:]\n",
    "#Transform string to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "maeList = []#for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dropMissingValues(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier_99\n",
      "\u001b[32mdone\u001b[0m \n",
      "\n",
      "starting z_score\n",
      "10.1\n",
      "\u001b[32mdone\u001b[0m \n",
      "\n",
      "starting knn\n",
      "3 1500\n",
      "\u001b[32mdone\u001b[0m \n",
      "\n",
      "starting db_scan\n",
      "4 500 0.6 8\n",
      "4 500 0.4 8\n",
      "\u001b[32mdone\u001b[0m \n",
      "\n",
      "starting noise\n",
      "5 5 10\n",
      "\u001b[32mdone\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Outlier Detection\n",
    "outlier_dict_all = {}\n",
    "\n",
    "if OUTLIER99 == True:\n",
    "    print(\"outlier_99\")\n",
    "    outlier_list_99 = get99(df) #TODO Mean for price for trainingsdata\n",
    "    df = drop99_all(df, outlier_list_99 )\n",
    "    #outlier_dict_all[\"99_mean\"] = outlier_list_99\n",
    "    #outlier_dict_all[\"99_drop\"] = outlier_list_99\n",
    "    print(green('done'), \"\\n\")\n",
    "\n",
    "print('starting z_score')\n",
    "for p in OUTLIER_ZSCORE[\"STD\"]:\n",
    "    print(p)\n",
    "    outlier_list_z_score = z_score(df, p)\n",
    "    outlier_dict_all[\"z_score_\"+str(p)] = outlier_list_z_score\n",
    "\n",
    "if OUTLIER_ZSCORE_IND == True:\n",
    "    outlier_list_z_score_ind = z_score_individual(df)\n",
    "\n",
    "print(green('done'), '\\n\\nstarting knn')\n",
    "for k in OUTLIER_KNN[\"K\"]:\n",
    "    for o in OUTLIER_KNN[\"X\"]:\n",
    "        print(k, o)\n",
    "        outlier_list_knn = outliers_knn(df, k, o, SPLIT_SIZE)\n",
    "        outlier_dict_all[\"knn_\"+str(k)+\"_\"+str(o)] = outlier_list_knn\n",
    "\n",
    "print(green('done'), '\\n\\nstarting db_scan')\n",
    "for k in OUTLIER_DBSCAN[\"K\"]:\n",
    "    for o in OUTLIER_DBSCAN[\"X\"]:\n",
    "        for e in OUTLIER_DBSCAN[\"EPS\"]:\n",
    "            for m in OUTLIER_DBSCAN[\"MIN_SAMPLES\"]:\n",
    "                print(k, o, e, m)\n",
    "                outlier_list_dbscan = outliers_dbscan(df, k, o, e, m, SPLIT_SIZE)\n",
    "                outlier_dict_all[\"db_scan_\"+str(k)+\"_\"+str(o)+\"_\"+str(e)+\"_\"+str(m)] = outlier_list_dbscan\n",
    "\n",
    "print(green('done'), '\\n\\nstarting noise')\n",
    "for cv in OUTLIER_NOISE[\"CV\"]:\n",
    "    for d in OUTLIER_NOISE[\"DEPTH\"]:\n",
    "        for m in OUTLIER_NOISE[\"MULTI\"]:\n",
    "            print(cv, d, m)\n",
    "            outlier_list_noise = getNoise(df, cv, d, m)\n",
    "            outlier_dict_all[\"noise_\"+str(cv)+\"_\"+str(d)+\"_\"+str(m)] = outlier_list_noise\n",
    "print(green('done'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('knn_3_1500', 'db_scan_4_500_0.4_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('knn_3_1500', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.4_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('knn_3_1500', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1mCombination: \u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \n",
      "\n",
      "\u001b[1m31\u001b[0m  total Combinations\n"
     ]
    }
   ],
   "source": [
    "outlier_lists_all = list(outlier_dict_all.values())\n",
    "outlier_lists_keys = list(outlier_dict_all.keys())\n",
    "combination_list = []\n",
    "for i, combo in enumerate(getCombinations(outlier_lists_keys), 1):\n",
    "    if not i == 1: #emtpy tuple\n",
    "        combination_list.append(combo)\n",
    "        # print('combo #{}: {}'.format(i, combo))\n",
    "print(\"...\")\n",
    "for c in combination_list[10:]:\n",
    "    print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "print(bold(len(combination_list)), \" total Combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorythm Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m0\u001b[0m: \u001b[36m('z_score_10.1',)\u001b[0m\n",
      "dropped \u001b[31m41\u001b[0m / 53 rows\n",
      "\n",
      "\u001b[1m1\u001b[0m: \u001b[36m('knn_3_1500',)\u001b[0m\n",
      "dropped \u001b[31m1500\u001b[0m / 1500 rows\n",
      "\n",
      "\u001b[1m2\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8',)\u001b[0m\n",
      "dropped \u001b[31m525\u001b[0m / 525 rows\n",
      "\n",
      "\u001b[1m3\u001b[0m: \u001b[36m('db_scan_4_500_0.4_8',)\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m4\u001b[0m: \u001b[36m('noise_5_5_10',)\u001b[0m\n",
      "dropped \u001b[31m35\u001b[0m / 51 rows\n",
      "\n",
      "\u001b[1m5\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500')\u001b[0m\n",
      "dropped \u001b[31m1536\u001b[0m / 1536 rows\n",
      "\n",
      "\u001b[1m6\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8')\u001b[0m\n",
      "dropped \u001b[31m562\u001b[0m / 562 rows\n",
      "\n",
      "\u001b[1m7\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m8\u001b[0m: \u001b[36m('z_score_10.1', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m76\u001b[0m / 76 rows\n",
      "\n",
      "\u001b[1m9\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8')\u001b[0m\n",
      "dropped \u001b[31m1534\u001b[0m / 1534 rows\n",
      "\n",
      "\u001b[1m10\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m11\u001b[0m: \u001b[36m('knn_3_1500', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1532\u001b[0m / 1532 rows\n",
      "\n",
      "\u001b[1m12\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m13\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m559\u001b[0m / 559 rows\n",
      "\n",
      "\u001b[1m14\u001b[0m: \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m15\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8')\u001b[0m\n",
      "dropped \u001b[31m1569\u001b[0m / 1569 rows\n",
      "\n",
      "\u001b[1m16\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m17\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1568\u001b[0m / 1568 rows\n",
      "\n",
      "\u001b[1m18\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m19\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m596\u001b[0m / 596 rows\n",
      "\n",
      "\u001b[1m20\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n",
      "\n",
      "\u001b[1m21\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m22\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1566\u001b[0m / 1566 rows\n",
      "\n",
      "\u001b[1m23\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m24\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m25\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m26\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1601\u001b[0m / 1601 rows\n",
      "\n",
      "\u001b[1m27\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n",
      "\n",
      "\u001b[1m28\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n",
      "\n",
      "\u001b[1m29\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m30\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n"
     ]
    }
   ],
   "source": [
    "model_obj_list = []\n",
    "for i, c in enumerate(combination_list):\n",
    "    print(f'\\n{bold(i)}: {blue(c)}')\n",
    "    outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "    try: \n",
    "        \n",
    "        # if \"99_mean\" in c:\n",
    "        #     X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"both\", outlier_list_99)\n",
    "        # else:\n",
    "        #     X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "        #df_price_rem = df.drop(columns=[\"price\"])\n",
    "        # print(df_price_rem[:2])\n",
    "        #print(df[:1])\n",
    "        X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\") #TODO drop entfernen\n",
    "\n",
    "        #TODO Regressionmodels\n",
    "        model = LinearRegression()\n",
    "        obj = Model(model, (X_train, X_test, y_train, y_test), c, df, df.columns.to_list())\n",
    "        model_obj_list.append(obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(bold(\"Error\"), red(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m0\u001b[0m: \u001b[36m('z_score_10.1',)\u001b[0m\n",
      "dropped \u001b[31m41\u001b[0m / 41 rows\n",
      "\n",
      "\u001b[1m1\u001b[0m: \u001b[36m('knn_3_1500',)\u001b[0m\n",
      "dropped \u001b[31m1500\u001b[0m / 1500 rows\n",
      "\n",
      "\u001b[1m2\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8',)\u001b[0m\n",
      "dropped \u001b[31m525\u001b[0m / 525 rows\n",
      "\n",
      "\u001b[1m3\u001b[0m: \u001b[36m('db_scan_4_500_0.4_8',)\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m4\u001b[0m: \u001b[36m('noise_5_5_10',)\u001b[0m\n",
      "dropped \u001b[31m35\u001b[0m / 35 rows\n",
      "\n",
      "\u001b[1m5\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500')\u001b[0m\n",
      "dropped \u001b[31m1536\u001b[0m / 1536 rows\n",
      "\n",
      "\u001b[1m6\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8')\u001b[0m\n",
      "dropped \u001b[31m562\u001b[0m / 562 rows\n",
      "\n",
      "\u001b[1m7\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m8\u001b[0m: \u001b[36m('z_score_10.1', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m76\u001b[0m / 76 rows\n",
      "\n",
      "\u001b[1m9\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8')\u001b[0m\n",
      "dropped \u001b[31m1534\u001b[0m / 1534 rows\n",
      "\n",
      "\u001b[1m10\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m11\u001b[0m: \u001b[36m('knn_3_1500', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1532\u001b[0m / 1532 rows\n",
      "\n",
      "\u001b[1m12\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m13\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m559\u001b[0m / 559 rows\n",
      "\n",
      "\u001b[1m14\u001b[0m: \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m15\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8')\u001b[0m\n",
      "dropped \u001b[31m1569\u001b[0m / 1569 rows\n",
      "\n",
      "\u001b[1m16\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m17\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1568\u001b[0m / 1568 rows\n",
      "\n",
      "\u001b[1m18\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m19\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m596\u001b[0m / 596 rows\n",
      "\n",
      "\u001b[1m20\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n",
      "\n",
      "\u001b[1m21\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3783\u001b[0m / 3783 rows\n",
      "\n",
      "\u001b[1m22\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1566\u001b[0m / 1566 rows\n",
      "\n",
      "\u001b[1m23\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m24\u001b[0m: \u001b[36m('db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m25\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8')\u001b[0m\n",
      "dropped \u001b[31m3814\u001b[0m / 3814 rows\n",
      "\n",
      "\u001b[1m26\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m1601\u001b[0m / 1601 rows\n",
      "\n",
      "\u001b[1m27\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n",
      "\n",
      "\u001b[1m28\u001b[0m: \u001b[36m('z_score_10.1', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n",
      "\n",
      "\u001b[1m29\u001b[0m: \u001b[36m('knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3808\u001b[0m / 3808 rows\n",
      "\n",
      "\u001b[1m30\u001b[0m: \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8', 'db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m\n",
      "dropped \u001b[31m3839\u001b[0m / 3839 rows\n"
     ]
    }
   ],
   "source": [
    "#model_obj_list = []\n",
    "for i, c in enumerate(combination_list):\n",
    "    print(f'\\n{bold(i)}: {blue(c)}')\n",
    "    outlier_list = get_unique_list(outlier_dict_all, c)\n",
    "    try: \n",
    "        X_train, X_test, y_train, y_test = splitData(df, SPLIT_SIZE, outlier_list, \"drop\")\n",
    "        df_lasso = train_test_to_df(X_train, X_test, y_train, y_test, df.columns.to_list())\n",
    "        X_l, y_l = df_lasso.drop(columns=[\"price\", \"date\", \"id\"]), df_lasso[\"price\"]\n",
    "        scaler = StandardScaler().fit(X_l)\n",
    "        X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_l, y_l, test_size = SPLIT_SIZE, random_state=1) #TODO \n",
    "        #rint(X_train_l)\n",
    "        X_train_l = scaler.transform(X_train_l)\n",
    "        X_test_l = scaler.transform(X_test_l)\n",
    "        \n",
    "        reg = Lasso(alpha=1)\n",
    "        obj_l = Model(reg, (X_train_l, X_test_l, y_train_l, y_test_l), c, df_lasso, X_l.columns.to_list())\n",
    "        model_obj_list.append(obj_l)\n",
    "        ''''''\n",
    "    except Exception as e:\n",
    "        print(bold(\"Error\"), red(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>dis_super</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>ahf1</th>\n",
       "      <th>ahf2</th>\n",
       "      <th>ahf3</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.438501e+09</td>\n",
       "      <td>1.418602e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>970.0</td>\n",
       "      <td>6828.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>640.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98106.0</td>\n",
       "      <td>47.5476</td>\n",
       "      <td>-122.360</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>11666.0</td>\n",
       "      <td>39.376922</td>\n",
       "      <td>114.928298</td>\n",
       "      <td>154.305220</td>\n",
       "      <td>315000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.598010e+08</td>\n",
       "      <td>1.425859e+18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>739.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98008.0</td>\n",
       "      <td>47.6301</td>\n",
       "      <td>-122.118</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>7896.0</td>\n",
       "      <td>82.463087</td>\n",
       "      <td>97.001643</td>\n",
       "      <td>179.464731</td>\n",
       "      <td>526000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.832060e+09</td>\n",
       "      <td>1.426464e+18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>5893.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98042.0</td>\n",
       "      <td>47.3333</td>\n",
       "      <td>-122.055</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>5757.0</td>\n",
       "      <td>58.893575</td>\n",
       "      <td>119.451791</td>\n",
       "      <td>178.345367</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.722069e+09</td>\n",
       "      <td>1.419811e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>100188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98038.0</td>\n",
       "      <td>47.3928</td>\n",
       "      <td>-122.066</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>104979.0</td>\n",
       "      <td>66.186721</td>\n",
       "      <td>109.383269</td>\n",
       "      <td>175.569991</td>\n",
       "      <td>540000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.268850e+09</td>\n",
       "      <td>1.428624e+18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027.0</td>\n",
       "      <td>47.5390</td>\n",
       "      <td>-122.026</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>64.025540</td>\n",
       "      <td>99.892763</td>\n",
       "      <td>163.918304</td>\n",
       "      <td>308000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id          date  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0  3.438501e+09  1.418602e+18       3.0       1.00        970.0    6828.0   \n",
       "1  2.598010e+08  1.425859e+18       4.0       2.00       1610.0    8000.0   \n",
       "2  3.832060e+09  1.426464e+18       4.0       2.50       2200.0    5893.0   \n",
       "3  1.722069e+09  1.419811e+18       3.0       2.50       3100.0  100188.0   \n",
       "4  9.268850e+09  1.428624e+18       3.0       1.75       1300.0    1237.0   \n",
       "\n",
       "   floors  waterfront  dis_super  view  ...  yr_renovated  zipcode      lat  \\\n",
       "0     1.0         0.0     640.05   0.0  ...           0.0  98106.0  47.5476   \n",
       "1     1.0         0.0     739.03   0.0  ...           0.0  98008.0  47.6301   \n",
       "2     2.0         0.0     501.91   0.0  ...           0.0  98042.0  47.3333   \n",
       "3     1.0         0.0     909.06   0.0  ...           0.0  98038.0  47.3928   \n",
       "4     2.0         0.0     479.66   0.0  ...           0.0  98027.0  47.5390   \n",
       "\n",
       "      long  sqft_living15  sqft_lot15       ahf1        ahf2        ahf3  \\\n",
       "0 -122.360         1160.0     11666.0  39.376922  114.928298  154.305220   \n",
       "1 -122.118         1560.0      7896.0  82.463087   97.001643  179.464731   \n",
       "2 -122.055         2200.0      5757.0  58.893575  119.451791  178.345367   \n",
       "3 -122.066         2430.0    104979.0  66.186721  109.383269  175.569991   \n",
       "4 -122.026         1350.0       942.0  64.025540   99.892763  163.918304   \n",
       "\n",
       "      price  \n",
       "0  315000.0  \n",
       "1  526000.0  \n",
       "2  280000.0  \n",
       "3  540000.0  \n",
       "4  308000.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lasso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>combo</th>\n",
       "      <th>mae</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(knn_3_1500, db_scan_4_500_0.6_8, db_scan_4_50...</td>\n",
       "      <td>100320.58</td>\n",
       "      <td>0.677609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan_4_500_0.4_8, noise_5_5_10)</td>\n",
       "      <td>100320.58</td>\n",
       "      <td>0.677609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(knn_3_1500, db_scan_4_500_0.4_8, noise_5_5_10)</td>\n",
       "      <td>100320.58</td>\n",
       "      <td>0.677609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan_4_500_0.6_8, db_scan_4_500_0.4_8, noi...</td>\n",
       "      <td>100320.58</td>\n",
       "      <td>0.677609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(z_score_10.1, knn_3_1500, db_scan_4_500_0.6_8...</td>\n",
       "      <td>103119.48</td>\n",
       "      <td>0.692954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(knn_3_1500, db_scan_4_500_0.4_8)</td>\n",
       "      <td>162867.97</td>\n",
       "      <td>0.431331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(db_scan_4_500_0.4_8,)</td>\n",
       "      <td>162867.97</td>\n",
       "      <td>0.431331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1,)</td>\n",
       "      <td>165149.5</td>\n",
       "      <td>0.525593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(z_score_10.1, noise_5_5_10)</td>\n",
       "      <td>165189.16</td>\n",
       "      <td>0.525594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>(noise_5_5_10,)</td>\n",
       "      <td>165189.86</td>\n",
       "      <td>0.525635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model                                              combo  \\\n",
       "60      Lasso(alpha=1)  (knn_3_1500, db_scan_4_500_0.6_8, db_scan_4_50...   \n",
       "45      Lasso(alpha=1)                (db_scan_4_500_0.4_8, noise_5_5_10)   \n",
       "54      Lasso(alpha=1)    (knn_3_1500, db_scan_4_500_0.4_8, noise_5_5_10)   \n",
       "55      Lasso(alpha=1)  (db_scan_4_500_0.6_8, db_scan_4_500_0.4_8, noi...   \n",
       "61      Lasso(alpha=1)  (z_score_10.1, knn_3_1500, db_scan_4_500_0.6_8...   \n",
       "..                 ...                                                ...   \n",
       "10  LinearRegression()                  (knn_3_1500, db_scan_4_500_0.4_8)   \n",
       "3   LinearRegression()                             (db_scan_4_500_0.4_8,)   \n",
       "0   LinearRegression()                                    (z_score_10.1,)   \n",
       "8   LinearRegression()                       (z_score_10.1, noise_5_5_10)   \n",
       "4   LinearRegression()                                    (noise_5_5_10,)   \n",
       "\n",
       "          mae     score  \n",
       "60  100320.58  0.677609  \n",
       "45  100320.58  0.677609  \n",
       "54  100320.58  0.677609  \n",
       "55  100320.58  0.677609  \n",
       "61  103119.48  0.692954  \n",
       "..        ...       ...  \n",
       "10  162867.97  0.431331  \n",
       "3   162867.97  0.431331  \n",
       "0    165149.5  0.525593  \n",
       "8   165189.16  0.525594  \n",
       "4   165189.86  0.525635  \n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary\n",
    "df_summary = pd.DataFrame(columns=['model', 'combo', 'mae', 'score'])\n",
    "for o in model_obj_list:\n",
    "    #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "    o.train()\n",
    "    mae, score = o.summary()\n",
    "    comb = o.get_comb()\n",
    "    row = {'model': o.get_model(), 'combo': comb, 'mae': mae, 'score': score}\n",
    "    df_summary = df_summary.append(row, ignore_index=True)\n",
    "\n",
    "df_summary.sort_values(\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel:\u001b[0m \u001b[36mLinearRegression()\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('z_score_10.1', 'knn_3_1500', 'db_scan_4_500_0.6_8')\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "number = 15\n",
    "print(model_obj_list[number])\n",
    "lassotest = model_obj_list[number]\n",
    "#print(lassotest.get_data()[0].shape, lassotest.get_data()[1].shape , lassotest.get_data()[2].shape, lassotest.get_data()[3].shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel:\u001b[0m \u001b[36mLasso(alpha=1)\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m22\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mae_best = df_summary[df_summary.mae==df_summary.mae.min()]\n",
    "#score_best = df_summary[df_summary.score==df_summary.score.max()]\n",
    "best_model_obj = getBestModel(model_obj_list, df_summary, mae_best.index[0])\n",
    "print(best_model_obj)\n",
    "#rint(f'{bold(\"Lowest mae:\")} {mae_best}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1mModel:\u001b[0m \u001b[36mLasso(alpha=1)\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m23\u001b[0m, \u001b[1mModel:\u001b[0m \u001b[36mLasso(alpha=1)\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m10\u001b[0m, \u001b[1mModel:\u001b[0m \u001b[36mLasso(alpha=1)\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m9\u001b[0m, \u001b[1mModel:\u001b[0m \u001b[36mLasso(alpha=1)\u001b[0m \u001b[1mCombination:\u001b[0m \u001b[36m('db_scan_4_500_0.4_8', 'noise_5_5_10')\u001b[0m \u001b[1mFeatures:\u001b[0m \u001b[36m9\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "model_obj_list_best = [best_model_obj]\n",
    "X_train, X_test, y_train, y_test = best_model_obj.get_data()\n",
    "\n",
    "df_feature_reduction = train_test_to_df(X_train, X_test, y_train, y_test, best_model_obj.get_features())\n",
    "#print(df_feature_reduction)\n",
    "\n",
    "for threshold in FEATURE_SEL_CORR[\"THRESHOLD_CORR\"]:\n",
    "    #print(threshold, type(threshold))\n",
    "    try: \n",
    "        rel_features = getRelFeatures(df_feature_reduction, threshold)\n",
    "        #print(len(rel_features), rel_features)\n",
    "        df_feature_reduction = df_feature_reduction[rel_features]\n",
    "        X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "        best_model_obj_new = Model(best_model_obj.get_model(), (X_train, X_test, y_train, y_test), best_model_obj.get_comb() , df_feature_reduction, df_feature_reduction.columns.to_list())\n",
    "        model_obj_list_best.append(best_model_obj_new)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(bold(\"Error\"), red(e))\n",
    "\n",
    "##manual feature selection\n",
    "rel_features_m = []\n",
    "\n",
    "print(model_obj_list_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>combo</th>\n",
       "      <th>mae</th>\n",
       "      <th>score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan_4_500_0.4_8, noise_5_5_10)</td>\n",
       "      <td>100320.58</td>\n",
       "      <td>0.677609</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan_4_500_0.4_8, noise_5_5_10)</td>\n",
       "      <td>109365.88</td>\n",
       "      <td>0.642075</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan_4_500_0.4_8, noise_5_5_10)</td>\n",
       "      <td>113435.67</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso(alpha=1)</td>\n",
       "      <td>(db_scan_4_500_0.4_8, noise_5_5_10)</td>\n",
       "      <td>113435.67</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model                                combo        mae     score  \\\n",
       "0  Lasso(alpha=1)  (db_scan_4_500_0.4_8, noise_5_5_10)  100320.58  0.677609   \n",
       "1  Lasso(alpha=1)  (db_scan_4_500_0.4_8, noise_5_5_10)  109365.88  0.642075   \n",
       "2  Lasso(alpha=1)  (db_scan_4_500_0.4_8, noise_5_5_10)  113435.67  0.592567   \n",
       "3  Lasso(alpha=1)  (db_scan_4_500_0.4_8, noise_5_5_10)  113435.67  0.592567   \n",
       "\n",
       "  features  \n",
       "0       22  \n",
       "1        9  \n",
       "2        8  \n",
       "3        8  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary\n",
    "df_summary_best = pd.DataFrame(columns=['model', 'combo', 'mae', 'score', 'features'])\n",
    "for o in model_obj_list_best:\n",
    "    #print(f'{o.get_type()}, {o.get_comb()}')\n",
    "    o.train()\n",
    "    mae, score = o.summary()\n",
    "    comb = o.get_comb()\n",
    "    features = o.get_features()\n",
    "    if \"price\" in features:\n",
    "        features.remove(\"price\")\n",
    "    row = {'model': o.get_model(),'combo': comb, 'mae': mae, 'score': score, 'features': len(features)}\n",
    "    df_summary_best = df_summary_best.append(row, ignore_index=True)\n",
    "\n",
    "df_summary_best.sort_values(\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #row\n",
    "# mae_best = df_summary_best[df_summary_best.mae==df_summary_best.mae.min()]\n",
    "# #score_best = df_summary_best[df_summary_best.score==df_summary_best.score.max()]\n",
    "# best_model_obj = getBestModel(model_obj_list_best, df_summary_best, mae_best.index[0])\n",
    "# print(best_model_obj)\n",
    "# print(f'{bold(\"Lowest mae:\")} {mae_best}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number = 15\n",
    "# print(model_obj_list[number])\n",
    "# lassotest = model_obj_list[number]\n",
    "# X_train, X_test, y_train, y_test =  lassotest.get_data()\n",
    "# X = np.append(X_train, X_test, axis=0)\n",
    "# print(type(y_test))\n",
    "# y = np.append(y_train, y_test.reshape(len(y_test), 1), axis=0)\n",
    "# print(X_train.shape, X_test.shape)\n",
    "# print(y_train.shape, y_test.shape)\n",
    "\n",
    "# X_y = np.append(X, y, axis=1)\n",
    "# features = df.columns.to_list()\n",
    "# df_adsa = pd.DataFrame(X_y, columns=features)\n",
    "\n",
    "# df_adsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_to_df(X_train, X_test, y_train, y_test, columns):\n",
    "#     X = np.append(X_train, X_test, axis=0)\n",
    "#     columns.remove(\"price\")\n",
    "#     columns.append(\"price\")\n",
    "#     #print(X_train.shape)\n",
    "#     print(\"X\", X.shape)\n",
    "#     try:\n",
    "#         y = np.append(y_train, y_test.reshape(len(y_test), 1), axis=0)\n",
    "\n",
    "#     except:\n",
    "#         y = np.append(y_train, y_test, axis=0)\n",
    "#         y = y.reshape(len(y), 1)\n",
    "        \n",
    "#     print(\"y\", y.shape)\n",
    "#     X_y = np.append(X, y, axis=1)\n",
    "#     print(\"X_y\", X_y.shape)\n",
    "#     #features = df.columns.to_list()\n",
    "#     df = pd.DataFrame(X_y, columns=columns)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_test_to_df(X_train, X_test, y_train, y_test, columns):\n",
    "#     X_train = pd.DataFrame(X_train, columns = df.columns.to_list().remove(\"price\"))\n",
    "#     X_test = pd.DataFrame(X_test, columns = df.columns.to_list().remove(\"price\"))\n",
    "#     y_train = pd.DataFrame(y_train, columns  = [\"price\"])\n",
    "#     y_test = pd.DataFrame(y_test, columns = [\"price\"])\n",
    "\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(df.columns.to_list())\n",
    "# X_train, X_test, y_train, y_test =  lassotest.get_data()\n",
    "\n",
    "# columnsList = lassotest.get_features()\n",
    "# #columnsList.remove(\"price\")\n",
    "\n",
    "# #columnsList.append(\"price\")\n",
    "# print(X_train.shape, X_test.shape,y_train.shape, y_test.shape)\n",
    "# train_test_to_df(X_train, X_test, y_train, y_test, columnsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressionmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(degree=2)\n",
    "# X_train, X_test, y_train, y_test = best_model_obj_new.get_data()\n",
    "# dff = train_test_to_df(X_train, X_test, y_train, y_test, best_model_obj_new.get_features())\n",
    "# poly.fit_transform(dff)\n",
    "# obj_l = Model(poly, best_model_obj_new.get_data(), best_model_obj_new.get_comb(), best_model_obj_new.get_df(), best_model_obj_new.get_features())\n",
    "# o = obj_l.train()\n",
    "# mae, score = obj_l.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluatuion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination_list = []\n",
    "# df_feature_reduction = best_model_obj.get_df()\n",
    "\n",
    "# for i, combo in enumerate(getCombinations(df_feature_reduction.columns.to_list()), 1):\n",
    "#     if not i == 1: #emtpy tuple\n",
    "#         combination_list.append(combo)\n",
    "#         # print('combo #{}: {}'.format(i, combo))\n",
    "# print(\"...\")\n",
    "# for c in combination_list[10:]:\n",
    "#     print(bold(\"Combination: \"), blue(c),\"\\n\",)\n",
    "# print(bold(len(combination_list)), \" total Combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_obj_list_best = []\n",
    "# df_feature_reduction = best_model_obj.get_df()\n",
    "# for i, c in enumerate(combination_list):\n",
    "#     print(f'\\n{bold(i)}: {blue(c)}')\n",
    "    \n",
    "#     try: \n",
    "#         X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "#         best_model_obj_copy = best_model_obj.copy()\n",
    "#         best_model_obj_copy.set_data(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#         model_obj_list_best.append(obj)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(bold(\"Error\"), red(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feature_reduction = best_model_obj.get_df()\n",
    "# getCombinations(df_feature_reduction.columns.to_list())\n",
    "\n",
    "# for feature in list(df_feature_reduction.columns.to_list()):\n",
    "#     df_feature_reduction.drop(columns=feature)\n",
    "#     X_train, X_test, y_train, y_test = splitData(df_feature_reduction, SPLIT_SIZE)\n",
    "#     best_model_obj_copy = best_model_obj.copy()\n",
    "#     best_model_obj_copy.set_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Wrapper approaches\n",
    "# #Backward elimination using Recursive feature elimination¶\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn import feature_selection\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# x, y = df.drop(columns=[\"price\"]), df[\"price\"]\n",
    "# # x_y= np.concatenate((x.reshape(150,4),y.reshape(150,1)),1)\n",
    "# x_y= np.concatenate((x,y),1)\n",
    "# #print(x_y)\n",
    "# #print(iris.target_names)\n",
    "\n",
    "# #Create column list\n",
    "# df_columns=df.columns\n",
    "# # df_columns.append(\"Label\")\n",
    "# # #Create PANDAS data frame\n",
    "# # df = pd.DataFrame(x_y,columns=df_columns)\n",
    "# #Map label index to label name\n",
    "# df['price']=df['price'].map(lambda x: iris.target_names[int(x)])\n",
    "# print(\"\\nOriginal Iris Data Set:\")\n",
    "# print(df)\n",
    "\n",
    "# #Create the RFE object and rank features\n",
    "# num_features=2\n",
    "# svc = SVC(kernel=\"linear\", C=1)\n",
    "# rfe = feature_selection.RFE(estimator=svc, n_features_to_select=num_features, step=1)\n",
    "# rfe.fit(x, y)\n",
    "# #print(\"Selected features will have a ranking=1 and support=TRUE\")\n",
    "# #print(iris.feature_names,\" \",rfe.ranking_,\" \",rfe.support_)\n",
    "# #print(x.shape)\n",
    "\n",
    "# #extend column-mask by one column for the label (always true)\n",
    "# column_mask=np.append(rfe.support_,True)\n",
    "# #use list column_mask to mask df-columns list\n",
    "# reduced_iris_features = [df_columns[i] for i in range(len(df_columns)) if column_mask[i]]\n",
    "# print(\"Reduced_iris_features: \",reduced_iris_features)\n",
    "# # use reduced_iris_features to reduce the data frame\n",
    "# reduced_df=df[reduced_iris_features]\n",
    "\n",
    "# print(\"\\nIris Data Set reduced to \",num_features,\" features: \\n\",reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO sqft_living wenn price auffällig niedrig obwohl m² hoch clsuter\n",
    "#TODO PCA macht warscheinlich wenig sinn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49d1cf207c92197553c1326cc52484d1ee2809997f5109c15474876a3e083b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
